{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, Normalizer, QuantileTransformer, PowerTransformer, MaxAbsScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen Kappa: 0.363 - Accuracy: 0.609\n",
      "Cohen Kappa: 0.279 - Accuracy: 0.562\n",
      "Cohen Kappa: 0.277 - Accuracy: 0.567\n",
      "Cohen Kappa: 0.391 - Accuracy: 0.646\n",
      "Cohen Kappa: 0.322 - Accuracy: 0.575\n",
      "Cohen Kappa: 0.318 - Accuracy: 0.583\n",
      "Cohen Kappa: 0.291 - Accuracy: 0.567\n",
      "Cohen Kappa: 0.445 - Accuracy: 0.646\n",
      "\n",
      "Cohan Kappa Médio: 0.336\n",
      "Accuracy Médio: 0.594\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# specify the directory containing the data\n",
    "train = pd.read_csv(r'C:\\Users\\55219\\Desktop\\Competicoes\\kaggle competitions download -c playground-series-s3e5\\train.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\55219\\Desktop\\Competicoes\\kaggle competitions download -c playground-series-s3e5\\test.csv')\n",
    "wineqt = train = pd.read_csv(r'C:\\Users\\55219\\Desktop\\Competicoes\\kaggle competitions download -c playground-series-s3e5\\WineQT.csv')\n",
    "\n",
    "# Retirando a coluna Id.\n",
    "train.drop(columns=['Id'], inplace=True)\n",
    "train = train.drop_duplicates()\n",
    " \n",
    "#train_wineqt = pd.concat([train, wineqt], axis=0)\n",
    "#train_wineqt = train_wineqt.drop_duplicates()\n",
    "\n",
    "#Separando as features que serão usadas no modelo.\n",
    "features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar','chlorides', 'free sulfur dioxide',\n",
    "             'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "\n",
    "X = train[features]\n",
    "y = train['quality']\n",
    "\n",
    "kf = KFold(n_splits=8, random_state=31, shuffle=True)\n",
    "\n",
    "soma_ck = 0\n",
    "soma_acc = 0\n",
    "#Implementando a validação cruzada\n",
    "for tr, ts in kf.split(X, y):\n",
    "    Xtr, Xval = X.iloc[tr], X.iloc[ts]\n",
    "    ytr, yval = y.iloc[tr], y.iloc[ts]\n",
    "    \n",
    "    #Instânciando o modelo\n",
    "    model_dt = RandomForestClassifier(n_estimators=500, random_state=31)\n",
    "\n",
    "    #Instânciando One vs Rest para multi class.\n",
    "    ovr_dt = OneVsRestClassifier(model_dt)\n",
    "\n",
    "    #Treinando o modelo\n",
    "    ovr_dt.fit(Xtr, ytr)\n",
    "\n",
    "    #Fazendo as previsões\n",
    "    pdt_ = ovr_dt.predict(Xval)\n",
    "    ck = cohen_kappa_score(yval, pdt_)\n",
    "    acc = accuracy_score(yval, pdt_)\n",
    "    #print(Xtr.shape)\n",
    "    #print(Xval.shape)\n",
    "    #print(ytr.shape)\n",
    "    #print(yval.shape)\n",
    "    print('Cohen Kappa: {:.3f} - Accuracy: {:.3f}'.format(ck, acc))\n",
    "    soma_ck += ck\n",
    "    soma_acc += acc\n",
    "print('')\n",
    "print('Cohan Kappa Médio: {:.3f}'.format(soma_ck/kf.n_splits))\n",
    "print('Accuracy Médio: {:.3f}'.format(soma_acc/kf.n_splits))\n",
    "    #primeiro cohen_kappa com dt e arvore de decisão - 0.19782921563924194\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observações:\n",
    "- Existem linhas duplicadas no dataset train original, mas por algum motivo o desempenho do nosso modelo é piorado quando eu treino sem esses dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
